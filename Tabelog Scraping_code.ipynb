{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabelog Scraping: Tokyo sushi restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Tabelog?**  \n",
    "Tabelog is an online restaurant information website. We can search restaurants using filters, and see the information about restaurants. For example, menus, addresses, contact information, photos, scores (ratings), and reviews. (It is like a OpenTable or Yelp.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in opening a sushi restaurant in Tokyo, this project is for you! We will acquire restaurant information from Tabelog to practice scraping. We focus on sushi restaurants in Tokyo!  \n",
    "  \n",
    "We will extract sushi restaurant information including: \n",
    "　　\n",
    "1. Restaurant names  \n",
    "2. Average scores  \n",
    "3. Number of reviews  \n",
    "4. Reviews (for dinner) 　     \n",
    "  \n",
    "At the end of this project, we will get two dataframes as CSV files. One is about restaurants, and another is about reviews! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the packages  \n",
    "2. Get the restaurant names and the restaurant page URLs from the search result  \n",
    "3. Get the average scores of the restaurants, the numbers of the reviews, and the URLs which the reviews are stored in  \n",
    "4. Make a restaurant dataframe  \n",
    "5. Get the reviews of each restaurant    \n",
    "6. Summary  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will use \"requests\" and \"BeautifulSoup\" libraries to extract data. \"tqdm\" library is to show the progresses of for-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# import re\n",
    "# import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle the code on/off.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see this notebook without codes\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle the code on/off.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the restaurant names and the restaurant page URLs from the search result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get the HTML of the restaurant list. To do so, go to the Tabelog website (https://tabelog.com/) and search \" 東京, 寿司\" (this meaning is \"Tokyo, Sushi\"). You will see a sushi restaurant list on your screen and get the URL (https://tabelog.com/tokyo/rstLst/sushi/1/?sk=%E5%AF%BF%E5%8F%B8&svd=20210104&svt=1900&svps=2). We will use this URL to get the restaurant names and the URLs. Also, check the number of the pages of the restaurant list. In this case, there are 60 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the request and get the HTML\n",
    "url = 'https://tabelog.com/tokyo/rstLst/sushi/1/?sk=%E5%AF%BF%E5%8F%B8&svd=20210104&svt=1900&svps=2'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Set a parser\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the tabelog website again to find the place where we can find the restaurant names and the restaurant URLs. They are in the `<a class='list-rst__rst-name-target'>` tag. Also, remember we have 60 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 60/60 [02:37<00:00,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# Prepare lists to keep restaurant names and the URLs\n",
    "restaurant_name_list = []\n",
    "restaurant_url_list = []\n",
    "\n",
    "# Send the request and get all of the restaurant names and the URLs from the 60 pages\n",
    "for i in tqdm(range(1, 61)): \n",
    "    url = 'https://tabelog.com/tokyo/rstLst/sushi/' + str(i) + '/?sk=%E5%AF%BF%E5%8F%B8&svd=20210104&svt=1900&svps=2'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Set a parser\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Get the elements in the <a class='list-rst__rst-name-target'> tab as a list\n",
    "    elements = soup.find_all('a', class_='list-rst__rst-name-target')\n",
    "    \n",
    "    for j in range(len(elements)):\n",
    "        restaurant_name_list.append(elements[j].contents[0])\n",
    "        restaurant_url_list.append(elements[j].attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get the average scores of the restaurants, the numbers of the reviews, and the URLs the reviews are stored in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access each of the restaurant URLs and get the average scores, the numbers of the reviews, and the URLs the reviews are stored in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1200/1200 [40:52<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# Prepare lists to keep the average scores, the numbers of the reviews, and the review URLs\n",
    "ave_score_list = []\n",
    "num_review_list = []\n",
    "review_url_list = []\n",
    "\n",
    "# Access each of the restaurant URLs in restaurant_URLs_list\n",
    "for res_url in tqdm(restaurant_url_list):\n",
    "    # Send the request and get the HTML\n",
    "    response = requests.get(res_url)\n",
    "    \n",
    "    # Set a parser\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Get the element in the <span class='rdheader-rating__score-val-dtl'> tab to get the score\n",
    "    element_score = soup.find('span', class_='rdheader-rating__score-val-dtl')\n",
    "    ave_score_list.append(element_score.contents[0])\n",
    "    \n",
    "    # Get the element in the <em class='num'> tab to get the number of the reviews\n",
    "    element_numReviews = soup.find('em', class_='num')\n",
    "    num_review_list.append(element_numReviews.contents[0])\n",
    "    \n",
    "    # Get the element in the <li id='rdnavi-review'> tab\n",
    "    element_revURL = soup.find('li', id='rdnavi-review')\n",
    "    # Get the URL from the <a> tab\n",
    "    review_url_list.append(element_revURL.a.get('href'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make a restaurant dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all of the restaurant names, the average scores, and the numbers of the reviews. Make a dataframe with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sushi restaurants: 1200\n",
      "The first 20 rows of df_restaurants\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>average_score</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>restaurant_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>七色てまりうた 新宿</td>\n",
       "      <td>3.28</td>\n",
       "      <td>69</td>\n",
       "      <td>https://tabelog.com/tokyo/A1304/A130401/13022043/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>弥栄</td>\n",
       "      <td>3.09</td>\n",
       "      <td>16</td>\n",
       "      <td>https://tabelog.com/tokyo/A1303/A130302/13238158/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>すし尽誠</td>\n",
       "      <td>3.50</td>\n",
       "      <td>61</td>\n",
       "      <td>https://tabelog.com/tokyo/A1311/A131101/13233806/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>恵比寿 鮨 おぎ乃</td>\n",
       "      <td>3.36</td>\n",
       "      <td>61</td>\n",
       "      <td>https://tabelog.com/tokyo/A1303/A130302/13223561/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>鮨 ふくじゅ</td>\n",
       "      <td>3.43</td>\n",
       "      <td>82</td>\n",
       "      <td>https://tabelog.com/tokyo/A1301/A130101/13228975/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>プレミアムレストラン 東京 金のダイニング 鮪金</td>\n",
       "      <td>3.37</td>\n",
       "      <td>38</td>\n",
       "      <td>https://tabelog.com/tokyo/A1301/A130101/13200206/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>鮨屋 小野</td>\n",
       "      <td>3.18</td>\n",
       "      <td>9</td>\n",
       "      <td>https://tabelog.com/tokyo/A1303/A130302/13045244/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>博多魚助 丸の内店</td>\n",
       "      <td>3.22</td>\n",
       "      <td>7</td>\n",
       "      <td>https://tabelog.com/tokyo/A1301/A130102/13227089/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUSHI B GINZA</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "      <td>https://tabelog.com/tokyo/A1301/A130101/13214841/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>代官山 鮨 たけうち</td>\n",
       "      <td>3.68</td>\n",
       "      <td>60</td>\n",
       "      <td>https://tabelog.com/tokyo/A1303/A130303/13210936/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>すしざんまい 湯島店</td>\n",
       "      <td>3.08</td>\n",
       "      <td>34</td>\n",
       "      <td>https://tabelog.com/tokyo/A1311/A131101/13132941/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>恵比寿 鮨 栞庵 やましろ</td>\n",
       "      <td>3.33</td>\n",
       "      <td>29</td>\n",
       "      <td>https://tabelog.com/tokyo/A1303/A130302/13249235/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>築地すし好 JIN仁 赤坂アークヒルズ店</td>\n",
       "      <td>3.38</td>\n",
       "      <td>24</td>\n",
       "      <td>https://tabelog.com/tokyo/A1307/A130701/13131704/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>鮨乃家 銀座二丁目店</td>\n",
       "      <td>3.24</td>\n",
       "      <td>27</td>\n",
       "      <td>https://tabelog.com/tokyo/A1301/A130101/13036612/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>寿し和 池袋店</td>\n",
       "      <td>3.24</td>\n",
       "      <td>25</td>\n",
       "      <td>https://tabelog.com/tokyo/A1305/A130501/13036573/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>鮨 喜一</td>\n",
       "      <td>3.22</td>\n",
       "      <td>32</td>\n",
       "      <td>https://tabelog.com/tokyo/A1303/A130302/13018544/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>うまい鮨勘 赤坂店</td>\n",
       "      <td>3.19</td>\n",
       "      <td>104</td>\n",
       "      <td>https://tabelog.com/tokyo/A1308/A130801/13002415/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>祭ずし 大森店</td>\n",
       "      <td>3.17</td>\n",
       "      <td>22</td>\n",
       "      <td>https://tabelog.com/tokyo/A1315/A131502/13008302/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>銀座寿司幸本店 丸ビル店</td>\n",
       "      <td>3.52</td>\n",
       "      <td>45</td>\n",
       "      <td>https://tabelog.com/tokyo/A1302/A130201/13000301/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>すしざんまい 上野</td>\n",
       "      <td>3.37</td>\n",
       "      <td>119</td>\n",
       "      <td>https://tabelog.com/tokyo/A1311/A131101/13097384/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             restaurant_name average_score num_reviews  \\\n",
       "0                 七色てまりうた 新宿          3.28          69   \n",
       "1                         弥栄          3.09          16   \n",
       "2                       すし尽誠          3.50          61   \n",
       "3                  恵比寿 鮨 おぎ乃          3.36          61   \n",
       "4                     鮨 ふくじゅ          3.43          82   \n",
       "5   プレミアムレストラン 東京 金のダイニング 鮪金          3.37          38   \n",
       "6                      鮨屋 小野          3.18           9   \n",
       "7                  博多魚助 丸の内店          3.22           7   \n",
       "8              SUSHI B GINZA          3.04           2   \n",
       "9                 代官山 鮨 たけうち          3.68          60   \n",
       "10                すしざんまい 湯島店          3.08          34   \n",
       "11             恵比寿 鮨 栞庵 やましろ          3.33          29   \n",
       "12      築地すし好 JIN仁 赤坂アークヒルズ店          3.38          24   \n",
       "13                鮨乃家 銀座二丁目店          3.24          27   \n",
       "14                   寿し和 池袋店          3.24          25   \n",
       "15                      鮨 喜一          3.22          32   \n",
       "16                 うまい鮨勘 赤坂店          3.19         104   \n",
       "17                   祭ずし 大森店          3.17          22   \n",
       "18              銀座寿司幸本店 丸ビル店          3.52          45   \n",
       "19                 すしざんまい 上野          3.37         119   \n",
       "\n",
       "                                       restaurant_url  \n",
       "0   https://tabelog.com/tokyo/A1304/A130401/13022043/  \n",
       "1   https://tabelog.com/tokyo/A1303/A130302/13238158/  \n",
       "2   https://tabelog.com/tokyo/A1311/A131101/13233806/  \n",
       "3   https://tabelog.com/tokyo/A1303/A130302/13223561/  \n",
       "4   https://tabelog.com/tokyo/A1301/A130101/13228975/  \n",
       "5   https://tabelog.com/tokyo/A1301/A130101/13200206/  \n",
       "6   https://tabelog.com/tokyo/A1303/A130302/13045244/  \n",
       "7   https://tabelog.com/tokyo/A1301/A130102/13227089/  \n",
       "8   https://tabelog.com/tokyo/A1301/A130101/13214841/  \n",
       "9   https://tabelog.com/tokyo/A1303/A130303/13210936/  \n",
       "10  https://tabelog.com/tokyo/A1311/A131101/13132941/  \n",
       "11  https://tabelog.com/tokyo/A1303/A130302/13249235/  \n",
       "12  https://tabelog.com/tokyo/A1307/A130701/13131704/  \n",
       "13  https://tabelog.com/tokyo/A1301/A130101/13036612/  \n",
       "14  https://tabelog.com/tokyo/A1305/A130501/13036573/  \n",
       "15  https://tabelog.com/tokyo/A1303/A130302/13018544/  \n",
       "16  https://tabelog.com/tokyo/A1308/A130801/13002415/  \n",
       "17  https://tabelog.com/tokyo/A1315/A131502/13008302/  \n",
       "18  https://tabelog.com/tokyo/A1302/A130201/13000301/  \n",
       "19  https://tabelog.com/tokyo/A1311/A131101/13097384/  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe having restaurant names, average scores, and the numbers of reviews\n",
    "df_restaurants = pd.DataFrame({'restaurant_name': restaurant_name_list, \n",
    "                              'average_score': ave_score_list,\n",
    "                              'num_reviews': num_review_list,\n",
    "                              'restaurant_url': restaurant_url_list})\n",
    "\n",
    "# Show the number of restaurants we got\n",
    "print('The number of sushi restaurants:', len(df_restaurants))\n",
    "\n",
    "# Show the first 20\n",
    "print('The first 20 rows of df_restaurants')\n",
    "\n",
    "df_restaurants[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 1,200 sushi restaurant information! If we analyze this dataframe, we will find which restaurants are popular and have high average scores. The \"-\" in the average_score column means the restaurant does not have any average score. The \"-\" in the num_reviews column means there is no review yet. If you want, we can extract the restaurant addresses, area, contact information and e.t.c. as well using the similar ways we did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only URLs having reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index number and the review_url_list of the restaurants having reviews\n",
    "restaurants_having_reviews = []\n",
    "\n",
    "for i in range(len(review_url_list)):\n",
    "    review_url = review_url_list[i]\n",
    "    if 'lrvwlst' in review_url:\n",
    "        have_reviews = {'restaurant_id': i, 'review_url':review_url}\n",
    "        restaurants_having_reviews.append(have_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get the reviews of each restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, get the reviews of each restaurant. This time, we will get up to 20 latest dinner reviews per restaurant because it takes time to get all the reviews (too many!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 1189/1189 [43:39<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Prepare lists to keep the restaurant ID and the review links\n",
    "restaurant_id_list = []\n",
    "full_review_url_list = []\n",
    "\n",
    "# Access each of the review URLs in restaurants_having_reviews\n",
    "for dic in tqdm(restaurants_having_reviews):\n",
    "    \n",
    "    # Get the review URL\n",
    "    review_url = dic['review_url']\n",
    "    \n",
    "    # Get the URL of dinner reviews\n",
    "    dinner_review_url = review_url + 'COND-2/smp1/?smp=1&lc=0&rvw_part=all'\n",
    "    \n",
    "    # Send the request and get the HTML\n",
    "    response = requests.get(dinner_review_url)\n",
    "    \n",
    "    # Set a parser\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Review links\n",
    "    # Get the elements in the <div class='rvw-item'> tab to get the review links\n",
    "    element_reviews = soup.find_all('div', class_='rvw-item')\n",
    "    \n",
    "    # Get the full review URL if there are any reviews\n",
    "    for elm in element_reviews:\n",
    "        full_review_url = 'https://tabelog.com' + elm.get('data-detail-url')\n",
    "        full_review_url_list.append(full_review_url)\n",
    "            \n",
    "    # Restaurant ID\n",
    "    # Add the restaurant id\n",
    "    restaurant_id_list.extend([dic['restaurant_id'] for _ in range(len(element_reviews))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of reviews we will get: 15689\n"
     ]
    }
   ],
   "source": [
    "# Check the number of elements in full_review_url_list\n",
    "print('The number of reviews we will get:', len(full_review_url_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 15,689 links having the full reviews. We will get each review, but it means we will access 15,689 times to the website. This is a lot. I will divide it into 4  to reduce the burden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 4000/4000 [2:07:18<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# Prepare list to keep the reviews\n",
    "review_list = []\n",
    "\n",
    "# To avoid a heavy burden, I devide 15689 accesses into 4 parts\n",
    "for url in tqdm(full_review_url_list[:4000]):\n",
    "    # Send the request and get the HTML of reviews\n",
    "    response_revs = requests.get(url)\n",
    "    \n",
    "    # Set a parser\n",
    "    soup_revs = BeautifulSoup(response_revs.text, 'html.parser')\n",
    "    \n",
    "    # Get the element in the <div class=\"rvw-item__rvw-comment\"> tab\n",
    "    element_revURL = soup_revs.find('div', class_='rvw-item__rvw-comment')\n",
    "    # Get the review (the first content)\n",
    "    review_list.append(element_revURL.p.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 4000/4000 [2:04:36<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(full_review_url_list[4000:8000]):\n",
    "    # Send the request and get the HTML of reviews\n",
    "    response_revs = requests.get(url)\n",
    "    \n",
    "    # Set a parser\n",
    "    soup_revs = BeautifulSoup(response_revs.text, 'html.parser')\n",
    "    \n",
    "    # Get the element in the <div class=\"rvw-item__rvw-comment\"> tab\n",
    "    element_revURL = soup_revs.find('div', class_='rvw-item__rvw-comment')\n",
    "    # Get the review (the first content)\n",
    "    review_list.append(element_revURL.p.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 4000/4000 [2:04:19<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(full_review_url_list[8000:12000]):\n",
    "    # Send the request and get the HTML of reviews\n",
    "    response_revs = requests.get(url)\n",
    "    \n",
    "    # Set a parser\n",
    "    soup_revs = BeautifulSoup(response_revs.text, 'html.parser')\n",
    "    \n",
    "    # Get the element in the <div class=\"rvw-item__rvw-comment\"> tab\n",
    "    element_revURL = soup_revs.find('div', class_='rvw-item__rvw-comment')\n",
    "    # Get the review (the first content)\n",
    "    review_list.append(element_revURL.p.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 3689/3689 [1:57:44<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(full_review_url_list[12000:]):\n",
    "    # Send the request and get the HTML of reviews\n",
    "    response_revs = requests.get(url)\n",
    "    \n",
    "    # Set a parser\n",
    "    soup_revs = BeautifulSoup(response_revs.text, 'html.parser')\n",
    "    \n",
    "    # Get the element in the <div class=\"rvw-item__rvw-comment\"> tab\n",
    "    element_revURL = soup_revs.find('div', class_='rvw-item__rvw-comment')\n",
    "    # Get the review (the first content)\n",
    "    review_list.append(element_revURL.p.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of reviews: 15689\n"
     ]
    }
   ],
   "source": [
    "# Check the number of reviews\n",
    "print('The total number of reviews:',len(review_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 15,689 reviews successfully! Let's make a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe having the restaurant IDs, scores, and reviews\n",
    "df_reviews = pd.DataFrame({'restaurant_id': restaurant_id_list, \n",
    "                           'reviews': review_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cannot show the reviews here because of the terms of use of Tabelog. This dataframe has two columns, 'restaurant_id' and 'reviews'. If you use both dataframes we made, you can say which restaurants have the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the two dataframes as csv files\n",
    "df_restaurants.to_csv('df_restaurant.csv')\n",
    "df_reviews.to_csv('df_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted 1,200 Tokyo sushi restaurant information (the names, average scores, and number of reviews) and 15,689 reviews by scraping using the requests library and BeautifulSoup library. This data can be used to analyze which restaurants are popular and have high average scores, what people expect to sushi restaurants in Tokyo and people like/dislike, and etc. I am planning to analyze this data as a different project soon! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabelog",
   "language": "python",
   "name": "tabelog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
